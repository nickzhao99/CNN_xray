{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import matplotlib\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadDataset(Dataset):\n",
    "    \"\"\"Loads a dataset and applies relevant transformations.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, imgcol, labelcol, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.dataframe = pd.read_csv(csv_file)\n",
    "        # if necessary, create dummies for a certain column\n",
    "        self.dataframe = pd.get_dummies(self.dataframe, columns=['Label'])\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.imgcol = imgcol\n",
    "        self.labelcol = labelcol\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.dataframe.iloc[idx, self.imgcol]) # fill with correct column\n",
    "        image = io.imread(img_name, as_gray=False, pilmode=\"RGB\") \n",
    "        label = self.dataframe.iloc[idx, self.labelcol] #fill with correct column of label\n",
    "        label = np.array(float(label))\n",
    "        sample = {'image': image, 'label': label}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rescale(object):\n",
    "    \"\"\"Rescale the image in a sample to a given size.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If tuple, output is\n",
    "            matched to output_size. If int, smaller of image edges is matched\n",
    "            to output_size keeping aspect ratio the same.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        if isinstance(self.output_size, int):\n",
    "            if h > w:\n",
    "                new_h, new_w = self.output_size * h / w, self.output_size\n",
    "            else:\n",
    "                new_h, new_w = self.output_size, self.output_size * w / h\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "\n",
    "        img = transform.resize(image, (new_h, new_w))\n",
    "        return {'image': img, 'label': label}\n",
    "    \n",
    "class CenterCrop(object):\n",
    "    \"\"\"Crop randomly the image in a sample.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If int, square crop\n",
    "            is made.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size) == 2\n",
    "            self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        new_h, new_w = self.output_size\n",
    "\n",
    "        top = np.random.randint(0, (h - new_h))\n",
    "        left = np.random.randint(0, (w - new_w))\n",
    "\n",
    "        image = image[top: top + new_h,\n",
    "                      left: left + new_w]\n",
    "\n",
    "        return {'image': image, 'label': label}\n",
    "    \n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "        image = image.transpose((2, 0, 1))\n",
    "\n",
    "        return {'image': torch.from_numpy(image),\n",
    "                'label': torch.from_numpy(label)}\n",
    "    \n",
    "import torch.nn.functional as F\n",
    "   \n",
    "class Normalize(object):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        mean (sequence): Sequence of means for each channel.\n",
    "        std (sequence): Sequence of standard deviations for each channel.\n",
    "        inplace(bool,optional): Bool to make this operation in-place.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mean, std, inplace=False):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.inplace = inplace\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "\n",
    "        image, label = sample['image'], sample['label']\n",
    "\n",
    "        image = F.normalize(image, self.mean, self.std, self.inplace)\n",
    "\n",
    "        return {'image': image, 'label': label}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_dataset = LoadDataset(csv_file='data_metadata.csv',\n",
    "                                    root_dir='data/train/1',\n",
    "                                      imgcol=1,\n",
    "                                      labelcol = 5,\n",
    "                                           transform=transforms.Compose([\n",
    "                                               Rescale(256),\n",
    "                                               CenterCrop(224),\n",
    "                                               ToTensor()\n",
    "                                           ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "dataloader = DataLoader(transformed_dataset, batch_size = batch_size, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 224, 224]) torch.Size([10]) 10 10\n"
     ]
    }
   ],
   "source": [
    "dataiter= iter(dataloader)\n",
    "data = dataiter.next()\n",
    "features = data[\"image\"]\n",
    "labels = data[\"label\"]\n",
    "print(features.shape,labels.shape, len(features), len(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 6, kernel_size= 5, stride=1, padding=2)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size = 2, stride = 1, padding = 0)\n",
    "        self.conv2 = nn.Conv2d(in_channels = 6, out_channels = 16, kernel_size = 5, stride=1, padding=2)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size = 2, stride = 1, padding = 0)\n",
    "        self.fc1 = nn.Linear(in_features = 16 * 222 * 222, out_features = 2) # outfeatues = Number of classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 222 * 222)\n",
    "        x = self.fc1(x) \n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "net = net.to(device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "[1,   100] loss: 0.283\n",
      "[1,   200] loss: 0.275\n",
      "[1,   300] loss: 0.287\n",
      "[1,   400] loss: 0.242\n",
      "[1,   500] loss: 0.262\n",
      "epoch 1\n",
      "[2,   100] loss: 0.267\n",
      "[2,   200] loss: 0.276\n",
      "[2,   300] loss: 0.265\n",
      "[2,   400] loss: 0.222\n",
      "[2,   500] loss: 0.237\n",
      "epoch 2\n",
      "[3,   100] loss: 0.271\n",
      "[3,   200] loss: 0.222\n",
      "[3,   300] loss: 0.236\n",
      "[3,   400] loss: 0.267\n",
      "[3,   500] loss: 0.242\n",
      "epoch 3\n",
      "[4,   100] loss: 0.208\n",
      "[4,   200] loss: 0.247\n",
      "[4,   300] loss: 0.295\n",
      "[4,   400] loss: 0.238\n",
      "[4,   500] loss: 0.243\n",
      "epoch 4\n",
      "[5,   100] loss: 0.197\n",
      "[5,   200] loss: 0.219\n",
      "[5,   300] loss: 0.236\n",
      "[5,   400] loss: 0.240\n",
      "[5,   500] loss: 0.227\n",
      "epoch 5\n",
      "[6,   100] loss: 0.217\n",
      "[6,   200] loss: 0.234\n",
      "[6,   300] loss: 0.246\n",
      "[6,   400] loss: 0.227\n",
      "[6,   500] loss: 0.219\n",
      "epoch 6\n",
      "[7,   100] loss: 0.241\n",
      "[7,   200] loss: 0.234\n",
      "[7,   300] loss: 0.187\n",
      "[7,   400] loss: 0.227\n",
      "[7,   500] loss: 0.213\n",
      "epoch 7\n",
      "[8,   100] loss: 0.230\n",
      "[8,   200] loss: 0.160\n",
      "[8,   300] loss: 0.334\n",
      "[8,   400] loss: 0.277\n",
      "[8,   500] loss: 0.197\n",
      "epoch 8\n",
      "[9,   100] loss: 0.221\n",
      "[9,   200] loss: 0.198\n",
      "[9,   300] loss: 0.223\n",
      "[9,   400] loss: 0.204\n",
      "[9,   500] loss: 0.250\n",
      "epoch 9\n",
      "[10,   100] loss: 0.204\n",
      "[10,   200] loss: 0.251\n",
      "[10,   300] loss: 0.217\n",
      "[10,   400] loss: 0.213\n",
      "[10,   500] loss: 0.199\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "    print(\"epoch \" + str(epoch))\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        inputs = data[\"image\"].to(device).float()\n",
    "        labels = data[\"label\"].to(device).long()\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:    # print every 100 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), './cifar_net.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the  test images: 90 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in dataloader:\n",
    "        inputs = data[\"image\"].to(device).float()\n",
    "        labels = data[\"label\"].to(device).long()\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the  test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.9492, -2.9909],\n",
       "        [ 1.7901, -1.8474],\n",
       "        [ 1.9008, -1.9491],\n",
       "        [ 1.0942, -1.1554],\n",
       "        [ 2.0068, -2.0782],\n",
       "        [ 2.3491, -2.3672],\n",
       "        [ 1.2740, -1.3063],\n",
       "        [ 1.6492, -1.6642],\n",
       "        [-0.7391,  0.6873],\n",
       "        [-2.2627,  2.2208]], device='cuda:0')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
